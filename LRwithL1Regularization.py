import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rc('font', family='Malgun Gothic')
plt.rcParams['axes.unicode_minus'] = False

class L1LogisticRegression:
    """L1 ì •ê·œí™” ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ í´ë˜ìŠ¤ (ë‹¨ê³„ë³„ ë””ë²„ê¹… ë²„ì „)"""
    
    def __init__(self, target_col='ì•”ì¢…', random_state=42):
        self.target_col = target_col
        self.random_state = random_state
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.model = None
        self.feature_names = None
        self.results = {}
        
        # ë‹¨ê³„ë³„ ë°ì´í„° ì €ì¥
        self.raw_data = None
        self.clean_data = None
        self.X_processed = None
        self.y_encoded = None
        self.best_c = None
        self.encoder = None  # LabelEncoderWithNA ì €ì¥
        
        print("ğŸ¯ L1 ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ ê°ì²´ ìƒì„±ë¨")
        print(f"   íƒ€ê²Ÿ ë³€ìˆ˜: {self.target_col}")
        print(f"   ëœë¤ ì‹œë“œ: {self.random_state}")
        print("   ğŸ’¡ LabelEncoderWithNA + fillna(0) ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ìœ„í•œ íŠ¹ë³„ ë²„ì „")
    
    def step1_check_data(self, df, encoder=None):
        """
        1ë‹¨ê³„: ë°ì´í„° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        df : pandas.DataFrame
            LabelEncoderWithNAë¡œ ì¸ì½”ë”©ëœ ë°ì´í„°í”„ë ˆì„
        encoder : LabelEncoderWithNA
            ì›ë³¸ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ ì¸ì½”ë” (ì„ íƒì‚¬í•­)
        """
        print("\nğŸ” 1ë‹¨ê³„: ë°ì´í„° ìƒíƒœ í™•ì¸")
        print("=" * 50)
        
        self.raw_data = df.copy()
        self.encoder = encoder
        
        # ê¸°ë³¸ ì •ë³´
        print(f"ğŸ“Š ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {df.shape}")
        print(f"ğŸ“Š íƒ€ê²Ÿ ë³€ìˆ˜: {self.target_col}")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ í™•ì¸
        if self.target_col in df.columns:
            target_values = df[self.target_col].dropna()
            target_counts = target_values.value_counts().sort_index()
            
            print(f"\nğŸ¯ {self.target_col} ë¶„í¬:")
            print("-" * 40)
            
            # ì¸ì½”ë”ê°€ ìˆìœ¼ë©´ ì›ë³¸ ê°’ìœ¼ë¡œ ë³€í™˜
            if encoder and hasattr(encoder, 'get_mapping'):
                target_mapping = encoder.get_mapping(self.target_col)
                inverse_mapping = {v: k for k, v in target_mapping.items()}
                
                for encoded_val, count in target_counts.items():
                    percentage = (count / len(target_values)) * 100
                    original_val = inverse_mapping.get(encoded_val, f"Unknown({encoded_val})")
                    if original_val == 'NA':
                        original_val = 'ê²°ì¸¡ê°’'
                    print(f"  {encoded_val} â†’ {original_val}: {count}ê°œ ({percentage:.1f}%)")
            else:
                for encoded_val, count in target_counts.items():
                    percentage = (count / len(target_values)) * 100
                    print(f"  {encoded_val}: {count}ê°œ ({percentage:.1f}%)")
            
            # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²´í¬
            min_class_ratio = target_counts.min() / target_counts.max()
            if min_class_ratio < 0.1:
                print(f"âš ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜• ì£¼ì˜! ìµœì†Œ/ìµœëŒ€ ë¹„ìœ¨: {min_class_ratio:.3f}")
            else:
                print(f"âœ… í´ë˜ìŠ¤ ê· í˜• ì–‘í˜¸. ìµœì†Œ/ìµœëŒ€ ë¹„ìœ¨: {min_class_ratio:.3f}")
        else:
            print(f"âŒ íƒ€ê²Ÿ ë³€ìˆ˜ '{self.target_col}'ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤!")
            return None
        
        # ê²°ì¸¡ê°’ í™•ì¸
        print(f"\nğŸ” ê²°ì¸¡ê°’ í˜„í™©:")
        print("-" * 30)
        missing_info = df.isnull().sum()
        missing_cols = missing_info[missing_info > 0]
        
        if len(missing_cols) > 0:
            print("ê²°ì¸¡ê°’ì´ ìˆëŠ” ì»¬ëŸ¼:")
            for col, count in missing_cols.head(10).items():  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
                percentage = (count / len(df)) * 100
                print(f"  {col}: {count}ê°œ ({percentage:.1f}%)")
            
            if len(missing_cols) > 10:
                print(f"  ... ë° {len(missing_cols)-10}ê°œ ì»¬ëŸ¼ ë”")
            
            # ê²°ì¸¡ê°’ ì œê±° í›„ í¬ê¸°
            df_clean = df.dropna()
            removed_rows = len(df) - len(df_clean)
            print(f"\nğŸ“‰ ê²°ì¸¡ê°’ ì œê±° í›„: {df_clean.shape} (ì œê±°ëœ í–‰: {removed_rows})")
            
            if removed_rows / len(df) > 0.5:
                print("âš ï¸  ë°ì´í„°ì˜ 50% ì´ìƒì´ ê²°ì¸¡ê°’ìœ¼ë¡œ ì œê±°ë©ë‹ˆë‹¤!")
        else:
            print("  âœ… ê²°ì¸¡ê°’ ì—†ìŒ")
            df_clean = df.copy()
        
        # ë°ì´í„° íƒ€ì…ê³¼ ê³ ìœ ê°’ í™•ì¸ (LabelEncoderWithNA ê²°ê³¼ ê³ ë ¤)
        print(f"\nğŸ“‹ ë°ì´í„° íƒ€ì… ë° ì¸ì½”ë”© í˜„í™©:")
        print("-" * 50)
        
        # ì¸ì½”ë” ì •ë³´ í™•ì¸
        if encoder and hasattr(encoder, 'get_mapping'):
            encoded_columns = list(encoder.get_mapping().keys())
            print(f"ğŸ“Š ì¸ì½”ë”©ëœ ì»¬ëŸ¼: {len(encoded_columns)}ê°œ")
            if len(encoded_columns) > 0:
                print(f"   ì˜ˆì‹œ: {encoded_columns[:5]}")
        
        # í˜¼ì¬ëœ íƒ€ì… ë¬¸ì œ ì²´í¬ (fillna(0) í›„ ë°œìƒ)
        mixed_type_columns = []
        numeric_columns = []
        
        for col in df.columns[:20]:  # ìƒìœ„ 20ê°œ ì»¬ëŸ¼ë§Œ ì²´í¬
            unique_vals = df[col].dropna().unique()
            
            # íƒ€ì… í˜¼ì¬ ì²´í¬
            has_numeric = any(isinstance(x, (int, float)) and not isinstance(x, bool) for x in unique_vals)
            has_string = any(isinstance(x, str) for x in unique_vals)
            
            if has_numeric and has_string:
                mixed_type_columns.append(col)
                print(f"âš ï¸  {col}: íƒ€ì… í˜¼ì¬ - {list(unique_vals[:5])} ...")
            elif has_numeric:
                numeric_columns.append(col)
                unique_count = len(unique_vals)
                
                # ì¸ì½”ë”©ëœ ê°’ê³¼ ì›ë³¸ ê°’ í‘œì‹œ
                if encoder and hasattr(encoder, 'get_mapping') and col in encoder.get_mapping():
                    mapping = encoder.get_mapping(col)
                    inverse_mapping = {v: k for k, v in mapping.items()}
                    
                    if unique_count <= 10:
                        original_vals = []
                        for val in sorted(unique_vals[:5]):
                            orig_val = inverse_mapping.get(val, f"Unknown({val})")
                            if orig_val == 'NA':
                                orig_val = 'ê²°ì¸¡ê°’'
                            original_vals.append(f"{val}â†’{orig_val}")
                        print(f"  {col}: {unique_count}ê°œ ê³ ìœ ê°’ â†’ {original_vals}")
                    else:
                        print(f"  {col}: {unique_count}ê°œ ê³ ìœ ê°’ (ì¸ì½”ë”©ë¨)")
                else:
                    if unique_count <= 10:
                        print(f"  {col}: {unique_count}ê°œ â†’ {list(unique_vals[:5])}")
                    else:
                        print(f"  {col}: {unique_count}ê°œ ê³ ìœ ê°’")
        
        print(f"\nğŸ“Š ë°ì´í„° íƒ€ì… ìš”ì•½:")
        print(f"  ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: {len(numeric_columns)}ê°œ")
        print(f"  íƒ€ì… í˜¼ì¬: {len(mixed_type_columns)}ê°œ")
        
        if mixed_type_columns:
            print(f"\nâš ï¸  íƒ€ì… í˜¼ì¬ ì»¬ëŸ¼ ë°œê²¬: {mixed_type_columns[:5]}")
            print("   fillna(0) ì²˜ë¦¬ë¡œ ì¸í•œ ê²ƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.")
            print("   ì „ì²˜ë¦¬ì—ì„œ íƒ€ì… í†µì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        self.clean_data = df_clean
        print(f"\nâœ… 1ë‹¨ê³„ ì™„ë£Œ. ì •ì œëœ ë°ì´í„°: {df_clean.shape}")
        return df_clean
    
    def step2_prepare_data(self, feature_cols=None, numeric_cols=None):
        """
        2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        LabelEncoderWithNA + fillna(0) ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ê³ ë ¤í•˜ì—¬ 
        ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì™€ ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜ë¥¼ êµ¬ë¶„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Parameters:
        -----------
        feature_cols : list
            ì‚¬ìš©í•  feature ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        numeric_cols : list
            ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¡œ ì²˜ë¦¬í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (CBC, ë‚˜ì´, í‚¤, ëª¸ë¬´ê²Œ ë“±)
        """
        print("\nğŸ”„ 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•/ì¹´í…Œê³ ë¦¬í˜• êµ¬ë¶„)")
        print("=" * 50)
        
        if self.clean_data is None:
            print("âŒ step1_check_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
            return None, None
        
        df = self.clean_data.copy()
        
        # ê¸°ë³¸ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì •ì˜ (CBC + ì¸êµ¬í†µê³„í•™ì  ìˆ˜ì¹˜ ë³€ìˆ˜)
        default_numeric_cols = [
            # CBC ë°ì´í„°
            'WBC', 'RBC', 'Hb', 'Hct', 'MCV', 'MCH', 'MCHC', 'RDW', 
            'PLT', 'PCT', 'MPV', 'PDW', 'ESR', 'Myelocyte', 'Metamyelocyte',
            'Band neutrophil', 'Segmented neutrophil', 'Lymphocyte', 'Monocyte',
            'Eosinophil', 'Basophil', 'Blast', 'Promonocyte', 'Promyelocyte',
            'Immature cell', 'Atypical lymphocyte', 'Normoblast', 'ANC',
            # ì¸êµ¬í†µê³„í•™ì  ìˆ˜ì¹˜ ë³€ìˆ˜  
            'AGE', 'Height', 'Weight', 'BMI'
        ]
        
        if numeric_cols is None:
            numeric_cols = default_numeric_cols
        
        # feature ì»¬ëŸ¼ ì„¤ì •
        if feature_cols is None:
            feature_cols = [col for col in df.columns if col != self.target_col]
            print(f"ğŸ“Š ëª¨ë“  ì»¬ëŸ¼ì„ featureë¡œ ì‚¬ìš©: {len(feature_cols)}ê°œ")
        else:
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
            available_cols = [col for col in feature_cols if col in df.columns]
            missing_cols = [col for col in feature_cols if col not in df.columns]
            
            if missing_cols:
                print(f"âš ï¸  ì—†ëŠ” ì»¬ëŸ¼ ì œì™¸: {missing_cols[:5]}...")
            
            feature_cols = available_cols
            print(f"ğŸ“Š ì‚¬ìš©í•  feature: {len(feature_cols)}ê°œ")
        
        # ìˆ˜ì¹˜í˜•ê³¼ ì¹´í…Œê³ ë¦¬í˜• ë¶„ë¦¬
        available_numeric_cols = [col for col in numeric_cols if col in feature_cols]
        categorical_feature_cols = [col for col in feature_cols if col not in numeric_cols]
        
        print(f"ğŸ“Š ë³€ìˆ˜ íƒ€ì… ë¶„ë¥˜:")
        print(f"  ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {len(available_numeric_cols)}ê°œ")
        print(f"  ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜: {len(categorical_feature_cols)}ê°œ")
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì²˜ë¦¬
        print(f"\nğŸ”¢ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì²˜ë¦¬ ì¤‘...")
        numeric_data = df[available_numeric_cols].copy()
        
        for col in available_numeric_cols:
            # ë¬¸ìì—´ì´ ì„ì—¬ìˆìœ¼ë©´ ìˆ«ìë¡œ ë³€í™˜
            if col in df.columns:
                original_type = numeric_data[col].dtype
                # ê°•ì œë¡œ ìˆ«ì ë³€í™˜
                numeric_data[col] = pd.to_numeric(numeric_data[col], errors='coerce')
                # NaNì„ 0ìœ¼ë¡œ ì±„ì›€
                numeric_data[col] = numeric_data[col].fillna(0)
                
                if original_type == 'object':
                    print(f"  {col}: {original_type} â†’ ìˆ˜ì¹˜í˜• ë³€í™˜")
        
        print(f"  ìˆ˜ì¹˜í˜• ë°ì´í„° í˜•íƒœ: {numeric_data.shape}")
        
        # ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜ ì²˜ë¦¬ (íƒ€ì… í˜¼ì¬ í•´ê²°)
        print(f"\nğŸ·ï¸  ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜ ì²˜ë¦¬ ì¤‘...")
        categorical_data = df[categorical_feature_cols].copy()
        
        for col in categorical_feature_cols:
            if col in df.columns:
                # íƒ€ì… í˜¼ì¬ í•´ê²°: ëª¨ë“  ê°’ì„ ë¬¸ìì—´ë¡œ í†µì¼
                unique_vals = categorical_data[col].dropna().unique()
                has_numeric = any(isinstance(x, (int, float)) and not isinstance(x, bool) for x in unique_vals)
                has_string = any(isinstance(x, str) for x in unique_vals)
                
                if has_numeric and has_string:
                    # ìˆ«ì 0ì„ ë¬¸ìì—´ '0'ìœ¼ë¡œ í†µì¼
                    categorical_data[col] = categorical_data[col].astype(str)
                    categorical_data[col] = categorical_data[col].replace(['0.0', '0'], '0')
                    print(f"  {col}: ë¬¸ìì—´ë¡œ í†µì¼ ë³€í™˜ (0 â†’ '0')")
                elif has_numeric:
                    # ëª¨ë‘ ìˆ«ìì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                    categorical_data[col] = categorical_data[col].astype(str)
                    categorical_data[col] = categorical_data[col].replace(['0.0'], '0')
                    print(f"  {col}: ë¬¸ìì—´ë¡œ ë³€í™˜")
        
        # NaNì„ '0'ìœ¼ë¡œ í†µì¼
        if categorical_data.isnull().any().any():
            categorical_data = categorical_data.fillna('0')
        
        print(f"  ì¹´í…Œê³ ë¦¬í˜• ë°ì´í„° í˜•íƒœ: {categorical_data.shape}")
        
        # ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”©
        if len(categorical_feature_cols) > 0:
            print(f"\nğŸ”„ ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”© ì¤‘...")
            categorical_encoded = pd.get_dummies(categorical_data, drop_first=True)
            print(f"  ì›-í•« ì¸ì½”ë”© í›„: {categorical_encoded.shape}")
        else:
            categorical_encoded = pd.DataFrame(index=df.index)
        
        # ìˆ˜ì¹˜í˜•ê³¼ ì¹´í…Œê³ ë¦¬í˜• ê²°í•©
        print(f"\nğŸ”— ìˆ˜ì¹˜í˜•ê³¼ ì¹´í…Œê³ ë¦¬í˜• ë°ì´í„° ê²°í•© ì¤‘...")
        X_encoded = pd.concat([numeric_data, categorical_encoded], axis=1)
        
        self.feature_names = X_encoded.columns.tolist()
        print(f"ğŸ“Š ìµœì¢… feature ìˆ˜: {len(self.feature_names)}ê°œ")
        print(f"  - ìˆ˜ì¹˜í˜•: {len(available_numeric_cols)}ê°œ")
        print(f"  - ì¹´í…Œê³ ë¦¬í˜• (ì›-í•«): {len(categorical_encoded.columns)}ê°œ")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ì²˜ë¦¬
        y = df[self.target_col].copy()
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ì²˜ë¦¬ (LabelEncoderWithNA ê³ ë ¤)
        print(f"\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ì „ì²˜ë¦¬...")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ë„ ë¬¸ìì—´ë¡œ í†µì¼ (ë§Œì•½ í˜¼ì¬ë˜ì–´ ìˆë‹¤ë©´)
        target_unique = y.dropna().unique()
        has_numeric = any(isinstance(x, (int, float)) and not isinstance(x, bool) for x in target_unique)
        has_string = any(isinstance(x, str) for x in target_unique)
        
        if has_numeric and has_string:
            y = y.astype(str)
            y = y.replace(['0.0', '0'], '0')
            print("  íƒ€ê²Ÿ ë³€ìˆ˜: ë¬¸ìì—´ë¡œ í†µì¼ ë³€í™˜")
        elif has_numeric:
            y = y.astype(str)
            y = y.replace(['0.0'], '0')
            print("  íƒ€ê²Ÿ ë³€ìˆ˜: ë¬¸ìì—´ë¡œ ë³€í™˜")
        
        unique_targets = sorted(y.unique())
        print(f"   íƒ€ê²Ÿ ê³ ìœ ê°’: {unique_targets}")
        
        # LabelEncoderWithNAì˜ ë§¤í•‘ì„ í™œìš©í•˜ì—¬ sklearn í˜¸í™˜ ì²˜ë¦¬
        if self.encoder and hasattr(self.encoder, 'get_mapping'):
            target_mapping = self.encoder.get_mapping(self.target_col)
            if target_mapping:
                print(f"   ì›ë³¸ ë§¤í•‘: {target_mapping}")
                
                # ë¬¸ìì—´ë¡œ ë³€í™˜ëœ ë§¤í•‘ ìƒì„±
                str_to_original = {}
                for original, encoded in target_mapping.items():
                    str_encoded = str(encoded)
                    str_to_original[str_encoded] = original
                
                # ìœ íš¨í•œ í´ë˜ìŠ¤ë§Œ ì„ íƒ ('0'ì€ ê²°ì¸¡ê°’ì´ë¯€ë¡œ ì œì™¸)
                valid_indices = y[y != '0'].index
                y_valid = y.loc[valid_indices]
                X_encoded = X_encoded.loc[valid_indices]
                
                # ì›ë³¸ ê°’ìœ¼ë¡œ ë³€í™˜ í›„ sklearn ì¸ì½”ë”©
                y_original = [str_to_original.get(str_val, 'Unknown') for str_val in y_valid]
                original_classes = sorted(list(set(y_original)))
                original_classes = [cls for cls in original_classes if cls != 'NA' and cls != 'Unknown']
                
                self.label_encoder.classes_ = np.array(original_classes)
                y_encoded = self.label_encoder.transform(y_original)
                
                print(f"   ìœ íš¨í•œ í´ë˜ìŠ¤: {original_classes}")
                print(f"   ê²°ì¸¡ê°’ ì œê±° í›„ ë°ì´í„° í¬ê¸°: X={X_encoded.shape}, y={len(y_encoded)}")
            else:
                print("âš ï¸  íƒ€ê²Ÿ ë³€ìˆ˜ ë§¤í•‘ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                y_valid = y[y != '0']
                X_encoded = X_encoded.loc[y_valid.index]
                y_encoded = self.label_encoder.fit_transform(y_valid)
        else:
            print("âš ï¸  LabelEncoderWithNA ì •ë³´ê°€ ì—†ì–´ ê¸°ë³¸ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            y_valid = y[y != '0']
            X_encoded = X_encoded.loc[y_valid.index]
            y_encoded = self.label_encoder.fit_transform(y_valid)
        
        print(f"\nğŸ“Š ìµœì¢… íƒ€ê²Ÿ í´ë˜ìŠ¤: {len(self.label_encoder.classes_)}ê°œ")
        print(f"   í´ë˜ìŠ¤ëª…: {list(self.label_encoder.classes_)}")
        
        # ìµœì¢… í™•ì¸
        print(f"\nâœ… 2ë‹¨ê³„ ì™„ë£Œ:")
        print(f"   X shape: {X_encoded.shape}")
        print(f"   y shape: {y_encoded.shape}")
        print(f"   X ë°ì´í„° íƒ€ì…: {X_encoded.dtypes.value_counts().to_dict()}")
        
        self.X_processed = X_encoded
        self.y_encoded = y_encoded
        
        return X_encoded, y_encoded
    
    def step3_explain_c_parameter(self):
        """
        3ë‹¨ê³„: C íŒŒë¼ë¯¸í„°ì˜ ì˜ë¯¸ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.
        """
        print("\nğŸ“š 3ë‹¨ê³„: C íŒŒë¼ë¯¸í„° ì´í•´í•˜ê¸°")
        print("=" * 50)
        print("L1 ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œ CëŠ” 'ì •ê·œí™” ê°•ë„ì˜ ì—­ìˆ˜'ì…ë‹ˆë‹¤.")
        print()
        print("ğŸ”¹ Cê°€ í´ìˆ˜ë¡ (ì˜ˆ: C=100)")
        print("   â†’ ì •ê·œí™” ì•½í•¨ â†’ ë” ë§ì€ íŠ¹ì„± ì‚¬ìš© â†’ ë³µì¡í•œ ëª¨ë¸")
        print("   â†’ ê³¼ì í•© ìœ„í—˜ ì¦ê°€, í•˜ì§€ë§Œ í›ˆë ¨ ë°ì´í„°ì— ì˜ ë§ìŒ")
        print()
        print("ğŸ”¹ Cê°€ ì‘ì„ìˆ˜ë¡ (ì˜ˆ: C=0.01)")
        print("   â†’ ì •ê·œí™” ê°•í•¨ â†’ ì ì€ íŠ¹ì„± ì‚¬ìš© â†’ ê°„ë‹¨í•œ ëª¨ë¸") 
        print("   â†’ ì–¸ë”í”¼íŒ… ìœ„í—˜ ì¦ê°€, í•˜ì§€ë§Œ ì¼ë°˜í™” ì„±ëŠ¥ ì¢‹ìŒ")
        print()
        print("ğŸ¯ ëª©í‘œ: ì ì ˆí•œ C ê°’ìœ¼ë¡œ í¸í–¥-ë¶„ì‚° íŠ¸ë ˆì´ë“œì˜¤í”„ ìµœì í™”!")
        print()
        print("ğŸ“ ìˆ˜ì‹:")
        print("   Cost = ë¡œì§€ìŠ¤í‹± ì†ì‹¤ + (1/C) Ã— Î£|ê³„ìˆ˜|")
        print("   ì—¬ê¸°ì„œ Î£|ê³„ìˆ˜|ê°€ L1 ì •ê·œí™” í•­ (Lasso)")
        print()
        print("ğŸ’¡ L1 ì •ê·œí™”ì˜ íŠ¹ì§•:")
        print("   - ì¼ë¶€ ê³„ìˆ˜ë¥¼ ì •í™•íˆ 0ìœ¼ë¡œ ë§Œë“¦ â†’ ìë™ íŠ¹ì„± ì„ íƒ")
        print("   - ì¤‘ìš”í•˜ì§€ ì•Šì€ ë³€ìˆ˜ë“¤ì´ ëª¨ë¸ì—ì„œ ì œê±°ë¨")
        print("   - í•´ì„í•˜ê¸° ì‰¬ìš´ sparseí•œ ëª¨ë¸ ìƒì„±")
    
    def step4_find_optimal_c(self, c_range=None, cv_folds=5):
        """
        4ë‹¨ê³„: êµì°¨ê²€ì¦ìœ¼ë¡œ ìµœì  C ê°’ì„ ì°¾ìŠµë‹ˆë‹¤.
        """
        print("\nğŸ¯ 4ë‹¨ê³„: ìµœì  C ê°’ íƒìƒ‰")
        print("=" * 40)
        
        if self.X_processed is None or self.y_encoded is None:
            print("âŒ step2_prepare_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”!")
            return None
        
        X, y = self.X_processed, self.y_encoded
        
        if c_range is None:
            c_range = [0.001, 0.01, 0.1, 1, 10]
        
        print(f"í…ŒìŠ¤íŠ¸í•  C ê°’ë“¤: {c_range}")
        print(f"êµì°¨ê²€ì¦ fold: {cv_folds}")
        print(f"ë°ì´í„° í¬ê¸°: {X.shape}")
        print()
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (ë§¤ìš° ì¤‘ìš”!)
        X_scaled = self.scaler.fit_transform(X)
        print("âœ… ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ")
        print("   (ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” íŠ¹ì„± ìŠ¤ì¼€ì¼ì— ë¯¼ê°í•˜ë¯€ë¡œ ë°˜ë“œì‹œ í•„ìš”)")
        
        # ê° C ê°’ì— ëŒ€í•´ êµì°¨ê²€ì¦ ìˆ˜í–‰
        results = []
        
        print("\nğŸ“Š C ê°’ë³„ êµì°¨ê²€ì¦ ê²°ê³¼:")
        print("-" * 55)
        print("    C ê°’    |  í‰ê·  ì •í™•ë„  |  í‘œì¤€í¸ì°¨  |  íŠ¹ì„± ìˆ˜")
        print("-" * 55)
        
        for C in c_range:
            # L1 ì •ê·œí™” ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸
            model = LogisticRegression(
                penalty='l1',           # L1 ì •ê·œí™” (Lasso)
                C=C,                   # ì •ê·œí™” ê°•ë„
                solver='liblinear',    # L1ì— ì í•©í•œ solver
                random_state=self.random_state,
                max_iter=1000
            )
            
            # êµì°¨ê²€ì¦ ìˆ˜í–‰
            cv_scores = cross_val_score(
                model, X_scaled, y,
                cv=StratifiedKFold(n_splits=cv_folds, shuffle=True, 
                                 random_state=self.random_state),
                scoring='accuracy'
            )
            
            # íŠ¹ì„± ì„ íƒ ê°œìˆ˜ í™•ì¸ (ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ)
            model.fit(X_scaled, y)
            selected_features = np.sum(np.abs(model.coef_) > 1e-6, axis=1).sum()
            
            mean_score = cv_scores.mean()
            std_score = cv_scores.std()
            
            results.append({
                'C': C,
                'mean_accuracy': mean_score,
                'std_accuracy': std_score,
                'cv_scores': cv_scores,
                'selected_features': selected_features
            })
            
            print(f"  {C:8.3f}  |   {mean_score:.4f}   |  {std_score:.4f}  |   {selected_features:3d}")
        
        print("-" * 55)
        
        # ìµœì  C ê°’ ì„ íƒ
        best_result = max(results, key=lambda x: x['mean_accuracy'])
        self.best_c = best_result['C']
        best_score = best_result['mean_accuracy']
        
        print(f"\nğŸ† ìµœì  ê²°ê³¼:")
        print(f"   ìµœì  C: {self.best_c}")
        print(f"   ìµœê³  ì •í™•ë„: {best_score:.4f} (Â±{best_result['std_accuracy']:.4f})")
        print(f"   ì„ íƒëœ íŠ¹ì„± ìˆ˜: {best_result['selected_features']}ê°œ / {len(self.feature_names)}ê°œ")
        
        # ì‹œê°í™”
        self._plot_c_validation(results)
        
        return self.best_c, results
    
    def _plot_c_validation(self, results):
        """C ê°’ ê²€ì¦ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        
        c_values = [r['C'] for r in results]
        mean_scores = [r['mean_accuracy'] for r in results]
        std_scores = [r['std_accuracy'] for r in results]
        feature_counts = [r['selected_features'] for r in results]
        
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        
        # ìƒë‹¨: ì •í™•ë„ ê·¸ë˜í”„
        ax1.errorbar(range(len(c_values)), mean_scores, yerr=std_scores,
                    marker='o', markersize=8, capsize=5, capthick=2, linewidth=2, color='blue')
        
        # ìµœì ê°’ í‘œì‹œ
        best_idx = c_values.index(self.best_c)
        ax1.scatter(best_idx, mean_scores[best_idx], color='red', s=150, zorder=5, 
                   label=f'ìµœì  C = {self.best_c}')
        
        ax1.set_xlabel('C ê°’')
        ax1.set_ylabel('êµì°¨ê²€ì¦ ì •í™•ë„')
        ax1.set_title('C ê°’ì— ë”°ë¥¸ ëª¨ë¸ ì„±ëŠ¥')
        ax1.set_xticks(range(len(c_values)))
        ax1.set_xticklabels([str(c) for c in c_values])
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        
        # í•˜ë‹¨: ì„ íƒëœ íŠ¹ì„± ìˆ˜
        ax2.bar(range(len(c_values)), feature_counts, alpha=0.7, color='green')
        ax2.set_xlabel('C ê°’')
        ax2.set_ylabel('ì„ íƒëœ íŠ¹ì„± ìˆ˜')
        ax2.set_title('C ê°’ì— ë”°ë¥¸ íŠ¹ì„± ì„ íƒ (L1 ì •ê·œí™” íš¨ê³¼)')
        ax2.set_xticks(range(len(c_values)))
        ax2.set_xticklabels([str(c) for c in c_values])
        ax2.grid(True, alpha=0.3, axis='y')
        
        # ìµœì ê°’ í‘œì‹œ
        ax2.bar(best_idx, feature_counts[best_idx], color='red', alpha=0.8,
               label=f'ìµœì  C = {self.best_c}')
        ax2.legend()
        
        plt.tight_layout()
        plt.savefig('c_validation_results.png', dpi=300)
        plt.show()
        
    
    def get_summary(self):
        """í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©ì„ ìš”ì•½í•©ë‹ˆë‹¤."""
        print("\nğŸ“‹ ì§„í–‰ ìƒí™© ìš”ì•½")
        print("=" * 40)
        
        if self.raw_data is not None:
            print(f"âœ… 1ë‹¨ê³„: ì›ë³¸ ë°ì´í„° {self.raw_data.shape}")
        
        if self.clean_data is not None:
            print(f"âœ… 1ë‹¨ê³„: ì •ì œ ë°ì´í„° {self.clean_data.shape}")
        
        if self.X_processed is not None:
            print(f"âœ… 2ë‹¨ê³„: ì „ì²˜ë¦¬ ì™„ë£Œ {self.X_processed.shape}")
            print(f"         íŠ¹ì„± ê°œìˆ˜: {len(self.feature_names)}")
            
        if self.best_c is not None:
            print(f"âœ… 4ë‹¨ê³„: ìµœì  C = {self.best_c}")
        
        print(f"\në‹¤ìŒ ë‹¨ê³„:")
        if self.raw_data is None:
            print("  â†’ step1_check_data() ì‹¤í–‰")
        elif self.X_processed is None:
            print("  â†’ step2_prepare_data() ì‹¤í–‰")
        elif self.best_c is None:
            print("  â†’ step3_explain_c_parameter() í™•ì¸")
            print("  â†’ step4_find_optimal_c() ì‹¤í–‰")
        else:
            print("  â†’ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì¤€ë¹„ ì™„ë£Œ!")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ğŸ’¡ ë‹¨ê³„ë³„ ì‚¬ìš©ë²• (LabelEncoderWithNA + fillna(0) ë°ì´í„°ìš©):")
    print("=" * 60)
    print("# 1. ê°ì²´ ìƒì„±")
    print("model = L1LogisticRegression(target_col='ì•”ì¢…')")
    print()
    print("# 2. ë‹¨ê³„ë³„ ì‹¤í–‰")
    print("model.step1_check_data(processed_encoded, encoder=encoder)")
    print("model.step2_prepare_data(feature_cols=feature_vars)  # ë˜ëŠ” None")
    print("model.step3_explain_c_parameter()")
    print("model.step4_find_optimal_c()")
    print()
    print("# 3. ì§„í–‰ ìƒí™© í™•ì¸")
    print("model.get_summary()")
    print()
    print("ğŸ¯ ì£¼ìš” ê°œì„ ì‚¬í•­:")
    print("  - LabelEncoderWithNAì˜ inverse_transform í™œìš©")
    print("  - fillna(0)ë¡œ ì¸í•œ íƒ€ì… í˜¼ì¬ ë¬¸ì œ í•´ê²°")
    print("  - ì¸ì½”ë”©ëœ ê°’ì„ ì›ë³¸ ê°’ìœ¼ë¡œ í‘œì‹œ")
    print("  - íƒ€ì… í†µì¼ ë° ì•ˆì •ì ì¸ ì „ì²˜ë¦¬")